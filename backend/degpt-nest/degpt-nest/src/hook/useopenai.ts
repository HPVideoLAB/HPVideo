import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';

/**
 * OpenAI GPT-5.2 Hook
 * ä½¿ç”¨å®˜æ–¹ OpenAI SDK è°ƒç”¨ GPT-5.2 Responses API
 */
@Injectable()
export class UseOpenAI {
  private readonly logger = new Logger(UseOpenAI.name);
  private readonly openai: OpenAI;

  constructor() {
    // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  /**
   * è°ƒç”¨ GPT-5.2 Responses API
   * @param systemPrompt ç³»ç»Ÿæç¤ºè¯
   * @param userPrompt ç”¨æˆ·æç¤ºè¯
   * @param options å¯é€‰é…ç½®
   * @returns GPT-5.2 å“åº”å†…å®¹
   */
  async callGPT52(
    systemPrompt: string,
    userPrompt: string,
    options?: {
      reasoningEffort?: 'none' | 'low' | 'medium' | 'high' | 'xhigh';
      verbosity?: 'low' | 'medium' | 'high';
      maxTokens?: number;
      temperature?: number;
    },
  ): Promise<string> {
    const {
      reasoningEffort = 'none',
      verbosity = 'medium',
      maxTokens = 10000,
      temperature = 0.85,
    } = options || {};

    this.logger.log(
      `[OpenAI] Calling GPT-5.2 | Reasoning: ${reasoningEffort} | Verbosity: ${verbosity}`,
    );

    try {
      // æ„å»ºå®Œæ•´çš„è¾“å…¥å†…å®¹ï¼ˆåˆå¹¶ system å’Œ user promptï¼‰
      const fullInput = `${systemPrompt}\n\n${userPrompt}`;

      // æ„å»ºè¯·æ±‚å‚æ•°
      const requestParams: any = {
        model: 'gpt-5.2',
        input: fullInput,
        reasoning: {
          effort: reasoningEffort,
        },
        text: {
          verbosity: verbosity,
        },
        max_output_tokens: maxTokens,
      };

      // åªæœ‰åœ¨ reasoning effort ä¸º none æ—¶æ‰æ”¯æŒ temperature
      if (reasoningEffort === 'none') {
        requestParams.temperature = temperature;
      }

      // ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Responses API
      const response: any = await this.openai.responses.create(requestParams);

      // ğŸ” è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”ç»“æ„
      this.logger.log(
        `[OpenAI Debug] Response structure: ${JSON.stringify(response, null, 2).slice(0, 1000)}`,
      );

      // ä»å“åº”ä¸­æå–å†…å®¹
      // å“åº”æ ¼å¼: { output: [{ content: [{ type: "output_text", text: "..." }] }] }
      let content: any = '';

      if (response?.output?.[0]) {
        const outputItem = response.output[0];

        // æ­£ç¡®çš„è·¯å¾„ï¼šoutput[0].content[0].text
        if (outputItem.content?.[0]?.text) {
          content = outputItem.content[0].text;
        } else {
          // å…¼å®¹å…¶ä»–å¯èƒ½çš„æ ¼å¼
          content = outputItem.text || outputItem.content || '';
        }
      }

      if (!content || typeof content !== 'string') {
        this.logger.error('[OpenAI] No valid content in response', response);
        throw new Error('No content returned from OpenAI API');
      }

      this.logger.log(
        `[OpenAI] Response received | Length: ${content.length} chars`,
      );

      return content;
    } catch (error: any) {
      this.logger.error(`[OpenAI] Request failed: ${error.message}`);
      throw error;
    }
  }

  /**
   * å¸¦é‡è¯•æœºåˆ¶çš„ GPT-5.2 è°ƒç”¨
   * @param systemPrompt ç³»ç»Ÿæç¤ºè¯
   * @param userPrompt ç”¨æˆ·æç¤ºè¯
   * @param options å¯é€‰é…ç½®
   * @param retries é‡è¯•æ¬¡æ•°
   * @returns GPT-5.2 å“åº”å†…å®¹
   */
  async callGPT52WithRetry(
    systemPrompt: string,
    userPrompt: string,
    options?: {
      reasoningEffort?: 'none' | 'low' | 'medium' | 'high' | 'xhigh';
      verbosity?: 'low' | 'medium' | 'high';
      maxTokens?: number;
      temperature?: number;
    },
    retries: number = 2,
  ): Promise<string> {
    let lastError: any;

    for (let i = 0; i < retries; i++) {
      try {
        return await this.callGPT52(systemPrompt, userPrompt, options);
      } catch (error: any) {
        lastError = error;

        // å¦‚æœæ˜¯ 504 æˆ– 502 é”™è¯¯ï¼Œé‡è¯•
        if (
          error.message.includes('504') ||
          error.message.includes('502') ||
          error.message.includes('Gateway Timeout')
        ) {
          if (i < retries - 1) {
            this.logger.warn(`[OpenAI] Retrying (${i + 1}/${retries})...`);
            continue;
          }
        }

        // å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
        throw error;
      }
    }

    throw lastError || new Error('OpenAI request failed after retries');
  }
}
