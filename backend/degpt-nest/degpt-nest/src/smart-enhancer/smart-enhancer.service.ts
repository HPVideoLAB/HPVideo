import { Injectable, Logger } from '@nestjs/common';

// å¯¼å‡ºè¿”å›ç»“æœæ¥å£
export interface OptimizedResult {
  videoPrompt: string;
  imageEditPrompt: string;
}

@Injectable()
export class SmartEnhancerService {
  private readonly logger = new Logger(SmartEnhancerService.name);

  // ==========================================
  // é…ç½®åŒºåŸŸ
  // ==========================================

  // 1. LLM é…ç½®
  private readonly DEGPT_URL = 'https://degpt.ai/api/v1/chat/completion/proxy';

  // ä½ çš„é‰´æƒ Token
  private readonly DEGPT_TOKEN =
    'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjB4ZGU4Nzg0MDExZTFDODY0RTM3Njk3ZmFFMjhhNkUxOWFlNEU2REQ5ZCIsImV4cCI6MTc2OTY3ODk0Mn0.yFJYgjMRU5V0t7pZeV4GM6PLZfHMcpv3if1d-k1bdEc';

  // æ¨¡å‹
  private readonly LLM_MODEL = 'gpt-5.2';

  // 2. Wavespeed é…ç½®
  private readonly WAVESPEED_URL = 'https://api.wavespeed.ai/api/v3';
  private readonly WAVESPEED_KEY =
    process.env.WAVESPEED_KEY || 'YOUR_WAVESPEED_KEY';

  /**
   * ä¸»å…¥å£
   */
  async runTest(originalPrompt: string, imageUrl?: string) {
    this.logger.log(
      `>>> å¯åŠ¨é¡¶çº§æ‘„å½±å¸ˆæµç¨‹ (GPT-5.2 Brain) Input: "${originalPrompt}"`,
    );

    // Step 1: æ‘„å½±å¸ˆ æ€è€ƒç”»é¢å¸ƒå±€
    const prompts = await this.optimizePrompts(originalPrompt);

    // Step 2: ä¿®å›¾å¸ˆ æ‰§è¡Œç”»é¢
    let optimizedImageUrl = imageUrl;
    if (imageUrl) {
      optimizedImageUrl = await this.optimizeImage(
        imageUrl,
        prompts.imageEditPrompt,
      );
    }

    this.logger.log('<<< æµç¨‹ç»“æŸ');

    return {
      originalInput: { prompt: originalPrompt, image: imageUrl },
      aiAnalysis: prompts,
      finalOutput: {
        videoPrompt: prompts.videoPrompt,
        startFrame: optimizedImageUrl,
      },
    };
  }

  // ==========================================
  // ğŸ”¥ æ ¸å¿ƒ A: é¡¶çº§æ‘„å½±å¸ˆæŒ‡ä»¤
  // ==========================================
  async optimizePrompts(originalPrompt: string): Promise<OptimizedResult> {
    this.logger.log(`[1/2] GPT-5.2 æ­£åœ¨æ„æ€æ„å›¾ä¸äººç‰©...`);

    const template = `
    Role: You are the world's TOP Commercial Photographer and Video Director.
    Task: Based on the user's input image description, create visual instructions for an AI Image Editor and a Video Generator.

    User Input: "${originalPrompt}"

    ---
    
    ### 1. RULES FOR "imageEditPrompt" (The Perfect Hero Shot):
    * **Rule #1 (Fidelity)**: START with "Keep the [product] design, logo, and shape 100% UNCHANGED."
    * **Rule #2 (Smart Model & Style Inference)**: 
        * **Demographics**: MUST use **"Stunning Asian/Korean model"** (K-pop star vibe, flawless skin).
        * **Gender Logic**:
            * IF product is masculine (e.g., Gaming, Men's Watch, Suit): Use "Handsome Asian Male Model".
            * IF product is feminine (e.g., Cosmetics, Jewelry): Use "Beautiful Asian Female Model".
            * IF neutral (e.g., Car, Coffee, Tech): Choose the most attractive option (e.g., Luxury Car -> Sexy/Elegant Female; Tech -> Cool Youth).
        * **Outfit & Vibe**:
            * Luxury Car/Nightlife -> **Sexy, High-fashion, Glamorous**.
            * Tea/Home/Cozy -> **Elegant, Soft-knits, Zen**.
            * Sports/Outdoors -> **Athletic, Energetic, Sweaty skin texture**.
    * **Rule #3 (Lighting & Vibe)**: Use professional terms: "Rembrandt Lighting", "Volumetric Fog", "Golden Hour", "Cyberpunk Neon" (if tech).
    * **Rule #4 (Realism)**: REAL LIFE textures. Pore-level skin detail, fabric stitching, material imperfections.

    ### 2. RULES FOR "videoPrompt" (The 20s Cinematic Ad):
    * Create a 20-second dynamic visual flow using **Advanced Camera Movements**.
    * **[0-5s] The Hook (Macro & Texture)**: 
        * Movement: **"Slow Macro Pan"** or **"Rack Focus"** (blur to sharp).
        * Focus on product texture, logo, or droplets.
    * **[5-15s] The Interaction (Emotion & Story)**: 
        * Movement: **"Orbit/Arc Shot"** (circling the subject) or **"Handheld Shake"** (for realism).
        * Action: The Asian model interacts with the product (sipping, driving, typing, applying). Capture micro-expressions (wink, slight smile, exhale).
    * **[15-20s] The Grand Reveal (Environment)**: 
        * Movement: **"Dolly Out"** (pull back fast) or **"Crane Shot"** (move up high).
        * Show the luxury context (Seoul skyline, high-end studio, nature).
    * **Keywords**: "8k", "Slow Motion 60fps", "Color Graded", "Unreal Engine 5 Render Style".

    ---
    **CRITICAL**: Output MUST be in **ENGLISH**.
    **Output strict JSON only:**
    {
      "imageEditPrompt": "...",
      "videoPrompt": "..."
    }
    `;

    try {
      const response = await fetch(this.DEGPT_URL, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.DEGPT_TOKEN}`,
        },
        body: JSON.stringify({
          model: this.LLM_MODEL,
          messages: [{ role: 'user', content: template }],
          stream: false,
          project: 'DecentralGPT',
          max_tokens: 2000,
          enable_thinking: false,
        }),
      });

      const textResponse = await response.text();
      // this.logger.debug(`Raw LLM Response: ${textResponse}`);

      let jsonStr = '';
      try {
        const data = JSON.parse(textResponse);

        // ğŸ”¥ [æ ¸å¿ƒä¿®å¤ç‚¹] å…¼å®¹å¤šç§è¿”å›æ ¼å¼
        let content = '';

        // 1. å°è¯• OpenAI æ ‡å‡†æ ¼å¼ (choices[0].message.content)
        if (data?.choices?.[0]?.message?.content) {
          content = data.choices[0].message.content;
        }
        // 2. å°è¯• DeGPT æ–°æ ¼å¼ (output[0].content[0].text)
        else if (data?.output?.[0]?.content?.[0]?.text) {
          content = data.output[0].content[0].text;
        }

        // æ­£åˆ™æå– JSON
        const match = content.match(/\{[\s\S]*\}/);
        if (match) jsonStr = match[0];
      } catch (e) {}

      if (!jsonStr) throw new Error('Valid JSON not found in LLM response');
      return JSON.parse(jsonStr);
    } catch (e) {
      this.logger.error('æç¤ºè¯ç”Ÿæˆå¤±è´¥', e);
      // é™çº§ç­–ç•¥
      return {
        imageEditPrompt: `Keep the product unchanged. A model's hand holding the product, cinematic lighting, photorealistic 4k. ${originalPrompt}`,
        videoPrompt: `Cinematic commercial. Macro shot of texture, slow motion interaction, dynamic lighting, 8k. ${originalPrompt}`,
      };
    }
  }

  // ==========================================
  // æ ¸å¿ƒ B: å›¾ç‰‡ä¼˜åŒ– (Nano Banana Pro)
  // ==========================================
  async optimizeImage(imageUrl: string, prompt: string): Promise<string> {
    this.logger.log(`[Image] æäº¤ç»™ Nano Banana Pro (4K)...`);

    // ğŸ”¥ [ä¿®å¤ç‚¹ 2] ä¹‹å‰ä½ è¿™é‡Œç›´æ¥ return äº†ï¼Œå¯¼è‡´å›¾ç‰‡æ²¡æœ‰ç”Ÿæˆ
    // return prompt;

    try {
      const payload = {
        prompt: prompt,
        images: [imageUrl],
        resolution: '4k',
        output_format: 'png',
        enable_sync_mode: false,
        num_outputs: 1,
        number_of_images: 1,
      };

      const submitRes = await fetch(
        `${this.WAVESPEED_URL}/google/nano-banana-pro/edit`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${this.WAVESPEED_KEY}`,
          },
          body: JSON.stringify(payload),
        },
      );

      const submitData = await submitRes.json();
      const requestId = submitData?.data?.id;

      if (!submitRes.ok || !requestId) {
        this.logger.error('Nano Banana æäº¤å¤±è´¥', submitData);
        return imageUrl;
      }

      this.logger.log(`ä»»åŠ¡ ID: ${requestId}ï¼Œå¼€å§‹ç­‰å¾…å‡ºå›¾...`);
      return await this.pollImageResult(requestId, imageUrl);
    } catch (e) {
      this.logger.error('å›¾ç‰‡ä¼˜åŒ–å¼‚å¸¸', e);
      return imageUrl;
    }
  }

  // ==========================================
  // è½®è¯¢å™¨
  // ==========================================
  private async pollImageResult(
    requestId: string,
    originalUrl: string,
  ): Promise<string> {
    const maxRetries = 120;
    const interval = 2000;

    for (let i = 0; i < maxRetries; i++) {
      await new Promise((r) => setTimeout(r, interval));

      try {
        const res = await fetch(
          `${this.WAVESPEED_URL}/predictions/${requestId}/result`,
          { headers: { Authorization: `Bearer ${this.WAVESPEED_KEY}` } },
        );

        if (!res.ok) continue;

        const json = await res.json();
        const status = json?.data?.status;

        if (status === 'completed') {
          const outputs = json.data.outputs;
          if (outputs && outputs.length > 0) {
            const finalUrl = outputs[0];
            this.logger.log(`âœ… æƒŠè‰³å›¾ç‰‡ç”ŸæˆæˆåŠŸ: ${finalUrl}`);
            return finalUrl;
          }
          return originalUrl;
        }

        if (status === 'failed') {
          this.logger.warn(`âŒ ä»»åŠ¡å¤±è´¥: ${json.data.error}`);
          return originalUrl;
        }
      } catch (e) {}
    }

    this.logger.warn('âŒ å›¾ç‰‡ä¼˜åŒ–è¶…æ—¶');
    return originalUrl;
  }
}
